{\em Dynamic multithreading} (DYM) \cite[Chapter 27]{Cormen2009} is a
model of parallel computation which is faithful to several industry standards
such as Intel's CilkPlus (\url{cilkplus.org}), OpenMP Tasks
(\url{openmp.org/wp}), and Threading Building
Blocks\break (\url{threadingbuildingblocks.org}).

In this model, a {\em multithreaded computation} is modelled as a directed
acyclic graph (DAG) $G=(V,E)$ where the set of vertices $V$ are instructions
and $(u,v) \in E$ if $u$ must be executed before $v$.\footnote{Notice that the
  RAM model is a subset of the DYM model where the outdegree of every
  vertex $v \in V$ is $\leq 1$.\Norbert{Why ``$\le$''?  Doesn't the strictly
    sequential nature of the RAM model mean that everybody except the first and
    last vertices has exactly one in-neighbour and one out-neighbour?}}
The time $T_p$ needed to execute the computation on $p$ processors depends on
two parameters of the computation: its {\em work} $T_1$ and its {\em span}
$T_\infty$.
Assuming each instruction takes constant time, the work is simpy the number of
nodes (i.e., instructions) in $G$.
Since each instruction takes constant time, it clearly takes $\Theta(T_1)$ time
to execute $G$ on a single processor.
More generally, $p$ processors can execute only $p$ instructions at a time, so
$T_p = \Omega(T_1/p)$.
The span is the length of the longest path in $G$.
Since the instructions on this path need to be executed one after another, no
matter how many processors we have at our disposal, we also have
$T_p = \Omega(T_\infty)$.
Together, these two lower bounds give $T_p = \Omega(T_\infty + T_1/p)$ and
work-stealing schedulers match this lower bound to within a constant factor
(to within a factor 2 from the optimal
performance)~\cite{Blumofe:1999:SMC:324133.324234}.
The degree to which an algorithm can take advantage of the presence of $p > 1$
processors is then captured by its {\em speed-up} $T_1 / T_p$ and its
{\em parallelism} $T_1 / T_\infty$.
In the absence of cache effects, the best speed-up one can hope for is $p$,
also known as {\em linear speed-up}.
The parallelism provides an upper bound on the achievable speed-up independent
of the number of available processors.

In order to describe parallel algorithms in the DYM model, we augment sequential
pseudocode with three special keywords.
The {\bf spawn} keyword, followed by a procedure call, indicates that the
procedure should run in its own thread and {\em may} thus be executed in parallel
to the thread that spawned the procedure call.
The {\bf sync} keyword indicates that the current thread must wait for all the
threads it has spawned to terminate before proceeding.
It thus provides a simple barrier-style synchronization mechanism.
Finally, {\bf parfor} is ``syntactic sugar'' for {\bf spawn}ing one thread per
iteration in a for loop, thereby allowing these iterations to run in parallel,
followed by a {\bf sync} operation that waits for all iterations to complete.
In practice, the overhead is logarithmic in the number of iterations.
If a procedure exits, either implicitly or explicitly using a {\bf return}
statement, it implicitly performs a {\bf sync} to ensure all threads it spawned
finish first.
\Norbert{Got rid of the ``strand'' stuff.
  It seems a technicality relevant only to the operation of work-stealing
  schedulers.
  If we actually use it in the analysis of the algorithm in Section 3, we
  may have to bring it back.}
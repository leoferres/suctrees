Lines 1--21 of Algorithm~\ref{algo:PSTA1} require $O(n)$ work and have
span~$O(n/p)$.
Line~22 requires $O(p)$ work and has span $O(\lg p)$ because we compute
a prefix sum over only $p$ values.
Lines~23--28 require $O(n/s)$ work and have span $O(n/sp)$.
Lines~1--6 of Algorithm~\ref{algo:PSTA2} require $O(n/s)$ work and have
span $O(n/sp)$.
Lines~7--10 require $O(p)$ work and have span $O(\lg p)$.
Algorithm \ref{algo:PSTA3} requires $O(\sqrt{2^w}\poly(w))$ work and
has span $O(\sqrt{2^{w}}\poly(w)/p)$.
Thus, the total work of {\tt PSTA} is $T_1 = O(n + \lg p + \sqrt{2^w}\poly(w))$
and its span is $O(n/p + \lg p + \sqrt{2^w}\poly(w)/p)$.
For $p \rightarrow \infty$, we get a span of $T_\infty = O(\lg n)$.
This gives a running time of $T_p = O(T_1/p + T_\infty) =
O(n/p + \lg p + \sqrt{2^w}\poly(w)/p)$ on $p$ cores.
The speedup is $T_1/T_p = O\left(\frac{p(n+\sqrt{2^{w}}\poly(w))}{n+\sqrt{2^{w}}\poly(w)+p\lg
p}\right)$. Under the assumption that $p\ll n$, the speedup approaches
$O(p)$. Moreover, the
parallelism $T_1/T_{\infty}$ (the maximum theoretical speedup) of {\tt
PSTA} is $\frac{n+\sqrt{2^{w}}\poly(w)}{\lg n}$.

An important advantage\Norbert{Advantage over which other algorithm?} of our algorithm is its working space. The {\tt
PSTA} algorithm does not need any extra memory related to the use of
threads. Indeed, it just needs space proportional to the input size
and the space needed to schedule the threads. A work-stealing
scheduler, like the one used by the DYM model, exhibits at most a
linear expansion space, that is, $O(S_1p)$, where $S_1$ is the minimum
amount of space used by the scheduler for any execution of a
multithreaded computation using one core. This upper bound is
optimal within a constant factor
\cite{Blumofe:1999:SMC:324133.324234}. In summary, the working space
needed by our algorithm is $O(n\lg n+S_1p)$ bits.\Norbert{I'm confused. $P$ needs $2n$ bits.  Our experiments claim that we use about 1 bit per element in $P$ of additional working space, so this would be $O(n)$ not $O(n \lg n)$.  Where does the extra space come from?  Either way, $O(n)$ or $O(n \lg n)$ is claimed out of the blue here without an argument where this bound on the amount of working space comes from.  This should be fixed.  We have the space to discuss this.} Thus, since in modern
machines it is usual that $p\ll n$, the scheduling space is negligible
and the working space is dominated by $O(n\lg n)$.

Note that in succinct data structure design, it is common to adopt the assumption that $w = \Theta(\lg n)$, and when constructing lookup tables, consider all possible bit vectors of length $(\lg n)/2$ (instead of $w/2$).
This guarantees that the universal lookup tables occupy only $o(n)$ bits.
Adopting the same strategy, we can simplify our analysis and obtain
$T_p = O(n/p + \lg p)$.
Thus, we have the following theorem:
\begin{theorem}\label{lem:lg}
A $(2n+o(n))$-bit representation of an ordinal tree on $n$ nodes and its balanced parenthesis sequence can be computed in $O(n/p + \lg p)$ time using $O(n\lg n)$ bits of working space, where $p$ is the number of cores.
This representation can support the operations in Table~\ref{tbl:operations} in $O(\lg n)$ time.
\end{theorem}
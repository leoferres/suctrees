Lines 1--21 of Algorithm~\ref{algo:PSTA1} require $O(n)$ work and have
span~$O(n/p)$.
Line~22 requires $O(p)$ work and has span $O(\lg p)$ because we compute
a prefix sum over only $p$ values.
Lines~23--28 require $O(n/s)$ work and have span $O(n/sp)$.
Lines~1--6 of Algorithm~\ref{algo:PSTA2} require $O(n/s)$ work and have
span $O(n/sp)$.
Lines~7--10 require $O(p)$ work and have span $O(\lg p)$.
Algorithm \ref{algo:PSTA3} requires $O(\sqrt{2^w}\poly(w))$ work and
has span $O(\sqrt{2^{w}}\poly(w)/p)$. As was defined in Section \ref{subsec:suctrees},
$w$ is the machine word size.
Thus, the total work of {\tt PSTA} is $T_1 = O(n + \lg p + \sqrt{2^w}\poly(w))$
and its span is $O(n/p + \lg p + \sqrt{2^w}\poly(w)/p)$.
For $p \rightarrow \infty$, we get a span of $T_\infty = O(\lg n)$.
This gives a running time of $T_p = O(T_1/p + T_\infty) =
O(n/p + \lg p + \sqrt{2^w}\poly(w)/p)$ on $p$ cores.
The speedup is $T_1/T_p = O\left(\frac{p(n+\sqrt{2^{w}}\poly(w))}{n+\sqrt{2^{w}}\poly(w)+p\lg
p}\right)$. Under the assumption that $p\ll n$, the speedup approaches
$O(p)$. Moreover, the
parallelism $T_1/T_{\infty}$ (the maximum theoretical speedup) of {\tt
PSTA} is $\frac{n+\sqrt{2^{w}}\poly(w)}{\lg n}$.

The {\tt PSTA} algorithm does not need any extra memory related to the use of
threads. Indeed, it just needs space proportional to the input size
and the space needed to schedule the threads. A work-stealing
scheduler, like the one used by the DyM model, exhibits at most a
linear expansion space, that is, $O(S_1p)$, where $S_1$ is the minimum
amount of space used by the scheduler for any execution of a
multithreaded computation using one core. This upper bound is
optimal within a constant factor
\cite{Blumofe:1999:SMC:324133.324234}. In summary, the working space
needed by our algorithm is $O(n\lg n+S_1p)$ bits. Since in our
algorithm the scheduler does not need to consider the input
size to schedule threads, $S_1=O(1)$. Thus, since in modern
machines it is usual that $p\ll n$, the scheduling space is negligible
and the working space is dominated by $O(n\lg n)$.

Note that in succinct data structure design, it is common to adopt the assumption that $w = \Theta(\lg n)$, and when constructing lookup tables, consider all possible bit vectors of length $(\lg n)/2$ (instead of $w/2$).
This guarantees that the universal lookup tables occupy only $o(n)$ bits.
Adopting the same strategy, we can simplify our analysis and obtain
$T_p = O(n/p + \lg p)$.
Thus, we have the following theorem:
\begin{theorem}\label{lem:lg}
A $(2n+o(n))$-bit representation of an ordinal tree on $n$ nodes and its balanced parenthesis sequence can be computed in $O(n/p + \lg p)$ time using $O(n\lg n)$ bits of working space, where $p$ is the number of cores.
This representation can support the operations in Table I of~\cite{Navarro:2014:FFS:2620785.2601073} in $O(\lg n)$ time.
\end{theorem}